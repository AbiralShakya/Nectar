Thermal-Time Training: Adaptive Energy-Constrained Inference for Mixture-of-Experts Models

The escalating energy consumption of large-scale machine learning models, particularly Mixture-of-Experts (MoE) architectures, presents a critical challenge to sustainable AI and deployment on power-constrained hardware. While current approaches focus on static model compression or power-aware pruning, they often lack the dynamic adaptability required for real-world inference in fluctuating environments. This paper introduces Thermal-Time Training (TTT), a novel framework that integrates Test-Time Training with MoE models to enable adaptive, energy-aware inference.

Our central hypothesis is that TTT can serve as a dynamic controller for model behavior under changing hardware and input conditions, guiding expert routing, computation depth, and precision on-the-fly without requiring full model re-training. We propose incorporating an explicit energy cost (estimated from real-time GPU power draw and expert-wise profiling) into the TTT objective, allowing the model to dynamically balance task performance with energy efficiency. This enables our system to: (1) adapt expert selection based on thermal budgets or power caps, (2) modulate computational pathways according to input complexity, and (3) gracefully degrade performance under hardware stress.

We demonstrate a practical system implementation with hooks for pynvml-based GPU profiling and provide a modular TTT component that leverages entropy minimization and selective parameter updates (e.g., router weights, BatchNorm stats). Our evaluation will showcase the trade-offs between accuracy, energy consumption (Joules/token, EDP), and throughput under various domain shifts and simulated hardware constraints. This work offers a crucial step towards building truly adaptive and energy-sustainable large-scale AI systems, providing both practical deployment strategies and interpretable insights into power-aware model behavior.