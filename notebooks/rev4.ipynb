{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dummy dataset\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n=1000, d_model=64):\n",
    "        self.data = torch.randn(n, d_model)\n",
    "        self.targets = torch.randn(n, d_model)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Dummy transformer wrapper\n",
    "class MoETransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_experts, top_k, thermal_signal_generator):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "        experts = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(num_experts)])\n",
    "        self.moe_layer = SimpleMoELayer(self.gate, experts, top_k, thermal_signal_generator=thermal_signal_generator)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe_layer(x)\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "d_model = 64\n",
    "num_experts = 8\n",
    "top_k = 2\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "dataset = DummyDataset(n=500, d_model=d_model)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "thermal_signal = ThermalSignalGenerator(device_id=0)\n",
    "model = MoETransformerBlock(d_model, num_experts, top_k, thermal_signal_generator=thermal_signal).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _, selected_experts = model(x)\n",
    "        task_loss = criterion(output, y)\n",
    "        energy_loss = compute_energy_loss(selected_expert_indices=selected_experts,\n",
    "                                          expert_profiles=thermal_signal.expert_profiles,\n",
    "                                          alpha=0.001)\n",
    "        loss = task_loss + energy_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} done. Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, Tuple, Optional, List, Any\n",
    "import time\n",
    "import numpy as np\n",
    "class SimpleMoELayer(nn.Module):\n",
    "    def __init__(self, gate: nn.Module, experts: nn.ModuleList, top_k: int = 2, capacity_factor: float = 1.25,\n",
    "                 thermal_signal_generator=None):\n",
    "        super().__init__()\n",
    "        self.gate = gate\n",
    "        self.experts = experts\n",
    "        self.n_experts = len(experts)\n",
    "        self.top_k = top_k\n",
    "        self.capacity_factor = capacity_factor\n",
    "\n",
    "        if top_k > self.n_experts:\n",
    "            raise ValueError(f\"top_k ({top_k}) cannot be greater than n_experts ({self.n_experts})\")\n",
    "\n",
    "        self.router = AdaptiveRouter(self.n_experts, top_k, thermal_signal_generator)\n",
    "        self.expert_timings: Dict[int, float] = {}\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        num_tokens, d_model = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        gate_logits = self.gate(x)\n",
    "        top_k_indices, top_k_probs = self.router(gate_logits)\n",
    "        gate_probs_all = F.softmax(gate_logits, dim=-1)\n",
    "\n",
    "        top1_indices = top_k_indices[:, 0]\n",
    "        expert_mask_top1 = F.one_hot(top1_indices, num_classes=self.n_experts).float()\n",
    "        tokens_per_expert_for_loss = expert_mask_top1.sum(dim=0)\n",
    "        fraction_per_expert = tokens_per_expert_for_loss / (num_tokens + 1e-8)\n",
    "        avg_gate_prob = gate_probs_all.mean(dim=0)\n",
    "        aux_loss = (fraction_per_expert * avg_gate_prob).sum() * self.n_experts\n",
    "\n",
    "        output = torch.zeros_like(x)\n",
    "        metrics: Dict[str, Any] = {}\n",
    "        expert_usage_counts = torch.zeros(self.n_experts, device=device)\n",
    "        expert_batch_timings: Dict[int, float] = {}\n",
    "\n",
    "        for expert_id in range(self.n_experts):\n",
    "            expert_tokens_mask = (top_k_indices == expert_id).any(dim=-1)\n",
    "            expert_token_indices = torch.where(expert_tokens_mask)[0]\n",
    "\n",
    "            if expert_token_indices.numel() > 0:\n",
    "                expert_input = x[expert_token_indices]\n",
    "\n",
    "                expert_weights_for_tokens = torch.zeros(expert_token_indices.numel(), device=device)\n",
    "                for i, token_idx in enumerate(expert_token_indices):\n",
    "                    pos_in_topk = torch.where(top_k_indices[token_idx] == expert_id)[0]\n",
    "                    if pos_in_topk.numel() > 0:\n",
    "                        expert_weights_for_tokens[i] = top_k_probs[token_idx, pos_in_topk].sum()\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.synchronize()\n",
    "                    start_event = torch.cuda.Event(enable_timing=True)\n",
    "                    end_event = torch.cuda.Event(enable_timing=True)\n",
    "                    start_event.record()\n",
    "                else:\n",
    "                    start_time = time.time()\n",
    "\n",
    "                expert_output = self.experts[expert_id](expert_input)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    end_event.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    duration_ms = start_event.elapsed_time(end_event)\n",
    "                else:\n",
    "                    duration_ms = (time.time() - start_time) * 1000.0\n",
    "\n",
    "                expert_batch_timings[expert_id] = duration_ms\n",
    "                self.expert_timings[expert_id] = self.expert_timings.get(expert_id, 0.0) + duration_ms\n",
    "\n",
    "                weighted_output = expert_output * expert_weights_for_tokens.unsqueeze(-1)\n",
    "                output[expert_token_indices] += weighted_output\n",
    "                expert_usage_counts[expert_id] = expert_token_indices.numel()\n",
    "\n",
    "        metrics['expert_usage_current'] = expert_usage_counts.cpu().numpy()\n",
    "        metrics['total_assignments'] = expert_usage_counts.sum().item()\n",
    "        metrics['expert_batch_timings_ms'] = expert_batch_timings\n",
    "        metrics['expert_cumulative_timings_ms'] = self.expert_timings\n",
    "\n",
    "        return output, aux_loss, metrics\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, n_experts: int = 8,\n",
    "                 top_k: int = 2, dropout: float = 0.1, use_moe: bool = True, capacity_factor: float = 1.25):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_moe = use_moe\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        if use_moe:\n",
    "            # Gating network for the MoE layer\n",
    "            gate_layer = nn.Linear(d_model, n_experts, bias=False)\n",
    "             # Initialize gate weights\n",
    "            nn.init.normal_(gate_layer.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "            # Create a ModuleList with n_experts distinct instances of the expert_module\n",
    "            experts_list = nn.ModuleList([\n",
    "                nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(dropout),\n",
    "                                   nn.Linear(d_ff, d_model)) for _ in range(n_experts)\n",
    "            ])\n",
    "\n",
    "            self.moe_layer = SimpleMoELayer(\n",
    "                gate=gate_layer,\n",
    "                experts=experts_list,\n",
    "                top_k=top_k,\n",
    "                capacity_factor=capacity_factor # Not used in SimpleMoELayer but kept for compatibility\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.feed_forward = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.Dropout(dropout),\n",
    "                                              nn.Linear(d_ff, d_model))\n",
    "\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "        profile: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Dict]:\n",
    "        \"\"\"\n",
    "        Forward pass with optional profiling.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor [batch_size, seq_len, d_model]\n",
    "            mask: Attention mask\n",
    "            profile: Whether to collect timing information\n",
    "\n",
    "        Returns:\n",
    "            output: Transformed tensor\n",
    "            metrics: Dictionary containing routing metrics and timings\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "\n",
    "        # Self-attention\n",
    "        residual = x\n",
    "        attn_out, attn_weights = self.attention(x, x, x, attn_mask=mask)\n",
    "        x = self.norm1(residual + self.dropout(attn_out))\n",
    "\n",
    "        # MoE or FFN\n",
    "        residual = x\n",
    "\n",
    "        if self.use_moe:\n",
    "            # Reshape input for MoE layer: [batch_size * seq_len, d_model]\n",
    "            batch_size, seq_len, d_model = x.shape\n",
    "            x_flat = x.view(-1, d_model)\n",
    "\n",
    "            # Profile MoE forward pass\n",
    "            if profile and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "                start_event = torch.cuda.Event(enable_timing=True)\n",
    "                end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "                start_event.record()\n",
    "\n",
    "            # MoE forward pass using SimpleMoELayer\n",
    "            # moe_metrics now includes expert-level timings and usage\n",
    "            moe_out_flat, aux_loss, moe_metrics = self.moe_layer(x_flat)\n",
    "\n",
    "            if profile and torch.cuda.is_available():\n",
    "                end_event.record()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "                total_time = start_event.elapsed_time(end_event)\n",
    "                metrics['moe_forward_time_ms'] = total_time\n",
    "\n",
    "            # Add all metrics from the moe_layer to the transformer block's metrics\n",
    "            metrics.update(moe_metrics)\n",
    "\n",
    "            # Reshape output back to [batch_size, seq_len, d_model]\n",
    "            moe_out = moe_out_flat.view(batch_size, seq_len, d_model)\n",
    "\n",
    "            x = residual + self.dropout(moe_out)\n",
    "            metrics['aux_loss'] = aux_loss\n",
    "\n",
    "        else:\n",
    "            # Standard FFN\n",
    "            if profile and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "                start_event = torch.cuda.Event(enable_timing=True)\n",
    "                end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "                start_event.record()\n",
    "                ffn_out = self.feed_forward(x)\n",
    "                end_event.record()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "                metrics['ffn_time_ms'] = start_event.elapsed_time(end_event)\n",
    "            else:\n",
    "                ffn_out = self.feed_forward(x)\n",
    "\n",
    "            x = residual + self.dropout(ffn_out)\n",
    "\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x, metrics\n",
    "\n",
    "\n",
    "class MoETransformer(nn.Module):\n",
    "    \"\"\"Simple MoE Transformer model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        d_model: int = 512,\n",
    "        n_heads: int = 8,\n",
    "        n_layers: int = 6,\n",
    "        d_ff: int = 2048,\n",
    "        n_experts: int = 8,\n",
    "        top_k: int = 2,\n",
    "        max_seq_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        use_moe_layers: Optional[list] = None,  # Which layers use MoE\n",
    "        capacity_factor: float = 1.25,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Determine which layers use MoE\n",
    "        if use_moe_layers is None:\n",
    "            # By default, use MoE in every other layer starting from layer 1\n",
    "            use_moe_layers = [i % 2 == 1 for i in range(n_layers)]\n",
    "        elif len(use_moe_layers) != n_layers:\n",
    "             raise ValueError(f\"Length of use_moe_layers ({len(use_moe_layers)}) must match n_layers ({n_layers})\")\n",
    "\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                d_model=d_model,\n",
    "                n_heads=n_heads,\n",
    "                d_ff=d_ff,\n",
    "                n_experts=n_experts,\n",
    "                top_k=top_k,\n",
    "                dropout=dropout,\n",
    "                use_moe=use_moe_layers[i],\n",
    "                capacity_factor=capacity_factor,\n",
    "            )\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Output projection\n",
    "        self.ln_f = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        profile: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            input_ids: Token indices [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            profile: Whether to collect profiling information\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing logits, aux_loss, and optional metrics\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        device = input_ids.device\n",
    "\n",
    "        # Embeddings\n",
    "        positions = torch.arange(0, seq_len, device=device).unsqueeze(0)\n",
    "        x = self.token_embedding(input_ids) + self.position_embedding(positions)\n",
    "\n",
    "        # Attention mask for causal modeling\n",
    "        if attention_mask is None:\n",
    "            # Create causal mask\n",
    "            causal_mask = torch.triu(\n",
    "                torch.ones(seq_len, seq_len, device=device), diagonal=1\n",
    "            ).bool()\n",
    "        else:\n",
    "            causal_mask = attention_mask\n",
    "\n",
    "        total_aux_loss = 0.0\n",
    "        all_metrics = {} if profile else None\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # Pass profiler instance to the layer if needed, or handle profiling inside layer\n",
    "            x, layer_metrics = layer(x, mask=causal_mask, profile=profile)\n",
    "\n",
    "            # Accumulate auxiliary loss from MoE layers\n",
    "            if 'aux_loss' in layer_metrics:\n",
    "                total_aux_loss += layer_metrics['aux_loss']\n",
    "\n",
    "            # Collect metrics\n",
    "            if profile:\n",
    "                for key, value in layer_metrics.items():\n",
    "                    if key != 'aux_loss':\n",
    "                        # Append metrics to lists if they exist, otherwise create\n",
    "                        metric_key = f'layer_{i}__{key}'\n",
    "                        if metric_key in all_metrics:\n",
    "                            if isinstance(all_metrics[metric_key], list) or isinstance(all_metrics[metric_key], dict):\n",
    "                                all_metrics[metric_key].append(value)\n",
    "                            else: # Convert to list if first time appending\n",
    "                                all_metrics[metric_key] = [all_metrics[metric_key], value]\n",
    "                        else:\n",
    "                            all_metrics[metric_key] = value\n",
    "\n",
    "\n",
    "        # Final layer norm and projection\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        output = {\n",
    "            'logits': logits,\n",
    "            'aux_loss': total_aux_loss,\n",
    "        }\n",
    "\n",
    "        if profile:\n",
    "            output['metrics'] = all_metrics\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynvml\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class ThermalSignalGenerator:\n",
    "    def __init__(self, device_id=0, update_interval=0.5):\n",
    "        self.device_id = device_id\n",
    "        self.update_interval = update_interval\n",
    "        self.expert_profiles = {}  # To be filled with real or estimated values\n",
    "        self.thermal_state = \"cool\"\n",
    "        self.expert_priorities = {}\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        self.handle = pynvml.nvmlDeviceGetHandleByIndex(device_id)\n",
    "        self._start_background_update()\n",
    "\n",
    "    def _start_background_update(self):\n",
    "        thread = threading.Thread(target=self._update_loop, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "    def _update_loop(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                temperature = pynvml.nvmlDeviceGetTemperature(self.handle, pynvml.NVML_TEMPERATURE_GPU)\n",
    "                power_draw = pynvml.nvmlDeviceGetPowerUsage(self.handle) / 1000.0  # mW -> W\n",
    "\n",
    "                if temperature > 85 or power_draw > 250:\n",
    "                    self.thermal_state = \"critical\"\n",
    "                elif temperature > 75:\n",
    "                    self.thermal_state = \"hot\"\n",
    "                elif temperature > 60:\n",
    "                    self.thermal_state = \"warm\"\n",
    "                else:\n",
    "                    self.thermal_state = \"cool\"\n",
    "\n",
    "                self._update_expert_priorities()\n",
    "            time.sleep(self.update_interval)\n",
    "\n",
    "    def _update_expert_priorities(self):\n",
    "        if self.thermal_state == \"cool\":\n",
    "            self.expert_priorities = {str(k): 0.0 for k in range(16)}  # uniform\n",
    "        elif self.thermal_state == \"warm\":\n",
    "            self.expert_priorities = {str(k): -0.1 * k for k in range(16)}\n",
    "        elif self.thermal_state == \"hot\":\n",
    "            self.expert_priorities = {str(k): -0.2 * k for k in range(16)}\n",
    "        elif self.thermal_state == \"critical\":\n",
    "            self.expert_priorities = {str(k): -0.5 * k for k in range(16)}\n",
    "\n",
    "    def get_expert_priorities(self):\n",
    "        with self.lock:\n",
    "            return self.expert_priorities.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import Dict, Tuple, Optional, List, Any\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class WikiText2Dataset(Dataset):\n",
    "    # just a simulation for now, skeleton code\n",
    "    def __init__(self, vocab_size: int = 1000, seq_len: int = 512, num_samples: int = 1000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_samples = num_samples\n",
    "        logging.info(f\"Initialized WikiText2Dataset with {num_samples} samples, seq_len={seq_len}, vocab_size={vocab_size}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        # Simulate text data: random token IDs\n",
    "        input_ids = torch.randint(0, self.vocab_size, (self.seq_len,))\n",
    "        # For language modeling, the target is usually the next token\n",
    "        labels = torch.cat([input_ids[1:], torch.tensor([0])]) # Simple shift\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "\n",
    "def evaluate_model(\n",
    "    model: MoETransformer,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    profiler: GPUProfiler, # Accept GPUProfiler instance\n",
    "    thermal_signal_generator: ThermalSignalGenerator, # Accept ThermalSignalGenerator instance\n",
    "    log_interval: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Performs an evaluation loop for the MoE model, logging inference time\n",
    "    and GPU metrics, and collecting thermal signals.\n",
    "\n",
    "    Args:\n",
    "        model: The MoETransformer model.\n",
    "        dataloader: DataLoader for the evaluation dataset.\n",
    "        device: Device to run evaluation on (e.g., 'cuda' or 'cpu').\n",
    "        profiler: GPUProfiler instance for logging metrics.\n",
    "        thermal_signal_generator: ThermalSignalGenerator instance.\n",
    "        log_interval: How often to log progress and metrics.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing average perplexity, total inference time,\n",
    "        average power draw, and aggregated MoE metrics.\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    inference_times_ms = []\n",
    "    power_draws_watts = []\n",
    "    temperatures_c = []\n",
    "    gpu_utilizations_percent = []\n",
    "\n",
    "    # Aggregated MoE metrics across all layers and batches\n",
    "    aggregated_moe_metrics: Dict[str, List[Any]] = {} # Use Any to handle dicts/lists\n",
    "\n",
    "    thermal_signals: List[ThermalSignal] = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    logging.info(f\"Starting evaluation on device: {device}\")\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculations\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Get thermal signal before computation\n",
    "            thermal_signal = thermal_signal_generator.get_thermal_signal()\n",
    "            if thermal_signal:\n",
    "                thermal_signals.append(thermal_signal)\n",
    "                # Log thermal state and recommendations\n",
    "                logging.info(\n",
    "                    f\"Batch {batch_idx+1} Thermal Signal: State={thermal_signal.thermal_state.value}, \"\n",
    "                    f\"PowerMode={thermal_signal.power_mode.value}, Temp={thermal_signal.temperature:.1f}°C, \"\n",
    "                    f\"Power={thermal_signal.power_draw:.1f}W\"\n",
    "                )\n",
    "                # Note: In a real system, you would use these signals to adapt model behavior\n",
    "                # (e.g., select different experts, apply throttle factors). For this\n",
    "                # baseline evaluation, we just log them.\n",
    "\n",
    "\n",
    "            # Measure inference time for the batch\n",
    "            if torch.cuda.is_available():\n",
    "                start_event = torch.cuda.Event(enable_timing=True)\n",
    "                end_event = torch.cuda.Event(enable_timing=True)\n",
    "                start_event.record()\n",
    "\n",
    "            # Forward pass with profiling enabled for MoE metrics\n",
    "            model_output = model(input_ids, profile=True) # Enable profiling in model for detailed metrics\n",
    "            logits = model_output['logits']\n",
    "            aux_loss = model_output.get('aux_loss', torch.tensor(0.0)).item()\n",
    "            metrics = model_output.get('metrics', {})\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                end_event.record()\n",
    "                torch.cuda.synchronize()\n",
    "                batch_inference_time_ms = start_event.elapsed_time(end_event)\n",
    "                inference_times_ms.append(batch_inference_time_ms)\n",
    "            else:\n",
    "                # Approximate time for CPU\n",
    "                batch_inference_time_ms = (time.time() - start_time) * 1000 # Rough estimate\n",
    "                inference_times_ms.append(batch_inference_time_ms)\n",
    "\n",
    "\n",
    "            # Calculate loss (for perplexity)\n",
    "            # Reshape logits and labels for CrossEntropyLoss\n",
    "            logits_flat = logits.view(-1, logits.size(-1))\n",
    "            labels_flat = labels.view(-1)\n",
    "            loss = F.cross_entropy(logits_flat, labels_flat, ignore_index=0) # Assuming 0 is padding/ignore\n",
    "\n",
    "            total_loss += loss.item() * labels.numel() # Accumulate loss weighted by number of elements\n",
    "            total_tokens += labels.numel()\n",
    "            total_batches += 1\n",
    "\n",
    "            # Collect and store GPU metrics for this batch\n",
    "            gpu_metrics = profiler.get_current_metrics()\n",
    "            if gpu_metrics:\n",
    "                power_draws_watts.append(gpu_metrics.power_draw)\n",
    "                temperatures_c.append(gpu_metrics.temperature)\n",
    "                gpu_utilizations_percent.append(gpu_metrics.gpu_utilization)\n",
    "\n",
    "            # Aggregate MoE specific metrics\n",
    "            if metrics:\n",
    "                for key, value in metrics.items():\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        # Convert arrays to lists for consistent aggregation\n",
    "                        value = value.tolist()\n",
    "\n",
    "                    if key not in aggregated_moe_metrics:\n",
    "                         aggregated_moe_metrics[key] = []\n",
    "\n",
    "                    if isinstance(value, (int, float, list)):\n",
    "                         aggregated_moe_metrics[key].append(value)\n",
    "                    elif isinstance(value, dict):\n",
    "                         # For dictionaries (like expert timings), aggregate per key\n",
    "                         for sub_key, sub_value in value.items():\n",
    "                             agg_key = f'{key}__{sub_key}' # e.g., 'expert_batch_timings_ms__0'\n",
    "                             if agg_key not in aggregated_moe_metrics:\n",
    "                                 aggregated_moe_metrics[agg_key] = []\n",
    "                             aggregated_moe_metrics[agg_key].append(sub_value)\n",
    "                    else:\n",
    "                         logging.warning(f\"Skipping aggregation for metric {key} with unsupported type {type(value)}\")\n",
    "\n",
    "\n",
    "            if (batch_idx + 1) % log_interval == 0:\n",
    "                avg_batch_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
    "                current_perplexity = math.exp(avg_batch_loss) if avg_batch_loss < 100 else float('inf') # Avoid overflow\n",
    "\n",
    "                log_msg = (\n",
    "                    f\"Batch {batch_idx+1}/{len(dataloader)} | \"\n",
    "                    f\"Loss: {avg_batch_loss:.4f} | \"\n",
    "                    f\"Perplexity: {current_perplexity:.2f} | \"\n",
    "                    f\"Batch Time: {batch_inference_time_ms:.2f} ms\"\n",
    "                )\n",
    "                # Log collected GPU metrics at log interval\n",
    "                if gpu_metrics:\n",
    "                    log_msg += (\n",
    "                        f\" | Power: {gpu_metrics.power_draw:.1f}W | \"\n",
    "                        f\"Temp: {gpu_metrics.temperature:.1f}°C | \"\n",
    "                        f\"GPU Util: {gpu_metrics.gpu_utilization:.1f}%\"\n",
    "                    )\n",
    "                logging.info(log_msg)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_inference_duration_sec = end_time - start_time\n",
    "\n",
    "    # Calculate overall averages\n",
    "    avg_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
    "    final_perplexity = math.exp(avg_loss) if avg_loss < 100 else float('inf')\n",
    "\n",
    "    # Calculate averages for collected GPU metrics\n",
    "    avg_inference_time_ms = np.mean(inference_times_ms) if inference_times_ms else 0\n",
    "    avg_power_draw_watts = np.mean(power_draws_watts) if power_draws_watts else 0\n",
    "    avg_temperature_c = np.mean(temperatures_c) if temperatures_c else 0\n",
    "    avg_gpu_utilization_percent = np.mean(gpu_utilizations_percent) if gpu_utilizations_percent else 0\n",
    "\n",
    "    # Aggregate MoE metrics (e.g., average expert usage across batches)\n",
    "    final_moe_metrics: Dict[str, Any] = {}\n",
    "    for key, values_list in aggregated_moe_metrics.items():\n",
    "        if not values_list:\n",
    "            continue\n",
    "\n",
    "        if isinstance(values_list[0], (int, float)):\n",
    "            final_moe_metrics[f'avg_{key}'] = np.mean(values_list)\n",
    "        elif isinstance(values_list[0], list) or isinstance(values_list[0], np.ndarray):\n",
    "             # For list/array metrics (like expert_usage), average the lists/arrays\n",
    "             # Ensure all lists/arrays have the same shape before averaging\n",
    "             try:\n",
    "                 final_moe_metrics[f'avg_{key}'] = np.mean([np.array(v) for v in values_list], axis=0).tolist()\n",
    "             except Exception as e:\n",
    "                 logging.warning(f\"Could not average list/array metric {key}: {e}\")\n",
    "                 final_moe_metrics[f'raw_{key}'] = values_list # Store raw list if averaging fails\n",
    "        elif isinstance(values_list[0], dict):\n",
    "             # This case should ideally be handled by the sub_key aggregation above,\n",
    "             # but as a fallback, log a warning.\n",
    "             logging.warning(f\"Metric {key} contains dictionaries, averaging not supported directly.\")\n",
    "             final_moe_metrics[f'raw_{key}'] = values_list # Store raw list of dicts\n",
    "\n",
    "    results = {\n",
    "        \"final_perplexity\": final_perplexity,\n",
    "        \"total_inference_duration_sec\": total_inference_duration_sec,\n",
    "        \"avg_inference_time_per_batch_ms\": avg_inference_time_ms,\n",
    "        \"avg_power_draw_watts\": avg_power_draw_watts,\n",
    "        \"avg_temperature_c\": avg_temperature_c,\n",
    "        \"avg_gpu_utilization_percent\": avg_gpu_utilization_percent,\n",
    "        \"aggregated_moe_metrics\": final_moe_metrics,\n",
    "        \"thermal_signals\": thermal_signals # Include collected thermal signals\n",
    "    }\n",
    "\n",
    "    logging.info(\"\\n--- Evaluation Summary ---\")\n",
    "    logging.info(f\"Final Perplexity: {final_perplexity:.2f}\")\n",
    "    logging.info(f\"Total Inference Duration: {total_inference_duration_sec:.2f} seconds\")\n",
    "    # Corrected access to avg_inference_time_per_batch_ms\n",
    "    logging.info(f\"Average Batch Inference Time: {results['avg_inference_time_per_batch_ms']:.2f} ms\")\n",
    "    if results['avg_power_draw_watts'] > 0:\n",
    "        logging.info(f\"Average Power Draw: {results['avg_power_draw_watts']:.1f} W\")\n",
    "        logging.info(f\"Average Temperature: {results['avg_temperature_c']:.1f} °C\")\n",
    "        logging.info(f\"Average GPU Utilization: {results['avg_gpu_utilization_percent']:.1f} %\")\n",
    "    logging.info(\"Aggregated MoE Metrics:\")\n",
    "    for k, v in final_moe_metrics.items():\n",
    "        # Format array output nicely\n",
    "        if isinstance(v, list) and all(isinstance(i, (int, float)) for i in v):\n",
    "             logging.info(f\"  {k}: {np.array(v)}\")\n",
    "        else:\n",
    "             logging.info(f\"  {k}: {v}\")\n",
    "\n",
    "    logging.info(\"\\nCollected Thermal Signals:\")\n",
    "    for i, signal in enumerate(results['thermal_signals']):\n",
    "         logging.info(f\"  Signal {i+1}: Temp={signal.temperature:.1f}°C, Power={signal.power_draw:.1f}W, State={signal.thermal_state.value}\")\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Main execution block ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # 1. Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    # 2. Initialize GPUProfiler\n",
    "    profiler = GPUProfiler()\n",
    "    profiler.start_profiling() # Start the profiling thread\n",
    "\n",
    "    # 3. Initialize ThermalSignalGenerator\n",
    "    # Assuming a default cost table exists or is handled by the class\n",
    "    thermal_signal_generator = ThermalSignalGenerator(profiler=profiler)\n",
    "    logging.info(\"ThermalSignalGenerator initialized.\")\n",
    "\n",
    "\n",
    "    # 4. Model Parameters (Adjust as needed for your specific MoE setup)\n",
    "    VOCAB_SIZE = 10000 # Example vocab size\n",
    "    D_MODEL = 512\n",
    "    N_HEADS = 8\n",
    "    N_LAYERS = 6\n",
    "    D_FF = 2048\n",
    "    N_EXPERTS = 8\n",
    "    TOP_K = 2\n",
    "    MAX_SEQ_LEN = 512\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "    # Set which layers use MoE (e.g., every other layer)\n",
    "    USE_MOE_LAYERS = [i % 2 == 1 for i in range(N_LAYERS)] # [False, True, False, True, False, True]\n",
    "\n",
    "    # 5. Instantiate MoE Model\n",
    "    logging.info(\"Initializing MoETransformer model...\")\n",
    "    model = MoETransformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        d_model=D_MODEL,\n",
    "        n_heads=N_HEADS,\n",
    "        n_layers=N_LAYERS,\n",
    "        d_ff=D_FF,\n",
    "        n_experts=N_EXPERTS,\n",
    "        top_k=TOP_K,\n",
    "        max_seq_len=MAX_SEQ_LEN,\n",
    "        use_moe_layers=USE_MOE_LAYERS\n",
    "    ).to(device)\n",
    "    logging.info(f\"Model instantiated with {sum(USE_MOE_LAYERS)} MoE layers.\")\n",
    "\n",
    "    # Optional: Load a pre-trained checkpoint if you have one\n",
    "    # checkpoint_path = \"path/to/your/checkpoint.pth\"\n",
    "    # if Path(checkpoint_path).exists():\n",
    "    #     logging.info(f\"Loading model checkpoint from {checkpoint_path}...\")\n",
    "    #     model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    #     logging.info(\"Model checkpoint loaded.\")\n",
    "    # else:\n",
    "    #     logging.warning(\"No model checkpoint found. Using randomly initialized weights.\")\n",
    "\n",
    "\n",
    "    # 6. Prepare Dataset and DataLoader (using simulated WikiText-2 for baseline)\n",
    "    # For actual WikiText-2, you'd use torchtext or similar to load and preprocess.\n",
    "    # Example: from torchtext.datasets import WikiText2\n",
    "    # For now, we use our dummy dataset.\n",
    "    logging.info(\"Preparing dataset...\")\n",
    "    eval_dataset = WikiText2Dataset(vocab_size=VOCAB_SIZE, seq_len=MAX_SEQ_LEN, num_samples=100) # Use a small number of samples for baseline\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    logging.info(f\"Evaluation DataLoader ready with {len(eval_dataloader)} batches.\")\n",
    "\n",
    "    # 7. Run Evaluation\n",
    "    logging.info(\"\\n--- Starting Baseline Inference Evaluation ---\")\n",
    "    baseline_results = evaluate_model(\n",
    "        model=model,\n",
    "        dataloader=eval_dataloader,\n",
    "        device=device,\n",
    "        profiler=profiler, # Pass the profiler instance\n",
    "        thermal_signal_generator=thermal_signal_generator, # Pass thermal signal generator\n",
    "        log_interval=10\n",
    "    )\n",
    "\n",
    "    # 8. Final Sanity Checks and Cleanup\n",
    "    logging.info(\"\\n--- Sanity Checks ---\")\n",
    "    if baseline_results['final_perplexity'] < float('inf'):\n",
    "        logging.info(f\"Perplexity sanity check: {baseline_results['final_perplexity']:.2f} (lower is better, typically starts high for untrained models)\")\n",
    "    else:\n",
    "        logging.warning(\"Perplexity is infinite. This might indicate issues like very high loss or training with random weights.\")\n",
    "\n",
    "    logging.info(f\"Average Power Draw: {baseline_results['avg_power_draw_watts']:.2f} W\")\n",
    "    logging.info(f\"Average Inference Time per Batch: {baseline_results['avg_inference_time_per_batch_ms']:.2f} ms\")\n",
    "\n",
    "    # Access detailed MoE metrics\n",
    "    if 'aggregated_moe_metrics' in baseline_results:\n",
    "        logging.info(\"\\nDetailed MoE Metrics (Averaged):\")\n",
    "        for key, value in baseline_results['aggregated_moe_metrics'].items():\n",
    "            logging.info(f\"  {key}: {value}\")\n",
    "\n",
    "    logging.info(\"\\nCollected Thermal Signals:\")\n",
    "    for i, signal in enumerate(baseline_results['thermal_signals']):\n",
    "         logging.info(f\"  Signal {i+1}: Temp={signal.temperature:.1f}°C, Power={signal.power_draw:.1f}W, State={signal.thermal_state.value}\")\n",
    "\n",
    "\n",
    "    profiler.stop_profiling() # Stop the profiling thread\n",
    "    logging.info(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access aggregated MoE metrics and thermal signals from the results\n",
    "aggregated_moe_metrics = baseline_results.get('aggregated_moe_metrics', {})\n",
    "thermal_signals = baseline_results.get('thermal_signals', [])\n",
    "\n",
    "print(\"\\n--- Detailed MoE Metrics Analysis ---\")\n",
    "if aggregated_moe_metrics:\n",
    "    for key, values_list in aggregated_moe_metrics.items():\n",
    "        if not values_list:\n",
    "            print(f\"  {key}: No data collected\")\n",
    "            continue\n",
    "\n",
    "        # Check if values_list is actually a list before accessing elements\n",
    "        if not isinstance(values_list, list):\n",
    "             # If it's not a list, it's likely a single scalar value already\n",
    "             print(f\"  {key.replace('avg_', '')}: {values_list}\")\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Handle different types of aggregated metrics (assuming values_list is now a list)\n",
    "        if 'usage_current' in key and values_list and isinstance(values_list[0], list):\n",
    "            # Expert usage is a list of counts per expert per batch\n",
    "            try:\n",
    "                avg_usage_per_expert = np.mean([np.array(v) for v in values_list if v is not None], axis=0) # Added check for None\n",
    "                print(f\"  Average {key.replace('avg_', '')} across batches: {avg_usage_per_expert}\")\n",
    "            except Exception as e:\n",
    "                 logging.warning(f\"Could not average list metric {key}: {e}\")\n",
    "                 print(f\"  Raw {key}: {values_list}\")\n",
    "\n",
    "        elif ('timings_ms' in key or 'time_ms' in key) and values_list and isinstance(values_list[0], float): # Added 'time_ms' check\n",
    "             # Expert batch timings or FFN timings are floats per batch\n",
    "             avg_timing = np.mean(values_list)\n",
    "             print(f\"  Average {key.replace('avg_', '')} across batches: {avg_timing:.2f} ms\")\n",
    "\n",
    "        elif 'cumulative_timings_ms' in key and values_list and isinstance(values_list[0], dict): # Changed to check for dict\n",
    "             # Cumulative timings are stored as dicts per batch\n",
    "             # Aggregate by summing up times for each expert across batches\n",
    "             total_cumulative_timings = defaultdict(float)\n",
    "             for batch_dict in values_list:\n",
    "                 if batch_dict: # Handle cases where the dict might be empty or None\n",
    "                     for expert_id, timing in batch_dict.items():\n",
    "                         total_cumulative_timings[expert_id] += timing\n",
    "\n",
    "             print(f\"  Total {key.replace('avg_', '')}: {dict(total_cumulative_timings)}\")\n",
    "\n",
    "        elif values_list and isinstance(values_list[0], (int, float)):\n",
    "            # Other simple scalar metrics collected across batches\n",
    "            print(f\"  {key.replace('avg_', '')}: {np.mean(values_list):.4f}\")\n",
    "        else:\n",
    "            print(f\"  Raw {key}: {values_list}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"No aggregated MoE metrics collected.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Thermal Signal Analysis ---\")\n",
    "if thermal_signals:\n",
    "    temperatures = [s.temperature for s in thermal_signals]\n",
    "    power_draws = [s.power_draw for s in thermal_signals]\n",
    "    thermal_states = [s.thermal_state for s in thermal_signals]\n",
    "    power_modes = [s.power_mode for s in thermal_signals]\n",
    "\n",
    "    print(f\"  Total Thermal Signals Collected: {len(thermal_signals)}\")\n",
    "    print(f\"  Temperature: Avg={np.mean(temperatures)}°C, Max={np.max(temperatures)}°C, Min={np.min(temperatures)}°C\") # Added min/max formatting\n",
    "    print(f\"  Power Draw: Avg={np.mean(power_draws)}W, Max={np.max(power_draws)}W, Min={np.min(power_draws)}W\") # Added min/max formatting\n",
    "\n",
    "    # Summarize thermal states and power modes\n",
    "    thermal_state_counts = {}\n",
    "    if thermal_signals: # Ensure thermal_signals is not empty before iterating\n",
    "        for state in ThermalState:\n",
    "            count = thermal_states.count(state)\n",
    "            if count > 0:\n",
    "                thermal_state_counts[state.value] = count\n",
    "        print(f\"  Thermal State Distribution: {thermal_state_counts}\")\n",
    "\n",
    "        power_mode_counts = {}\n",
    "        for mode in PowerMode:\n",
    "            count = power_modes.count(mode)\n",
    "            if count > 0:\n",
    "                power_mode_counts[mode.value] = count\n",
    "        print(f\"  Power Mode Distribution: {power_mode_counts}\")\n",
    "\n",
    "else:\n",
    "    print(\"No thermal signals collected.\")\n",
    "\n",
    "# Access aggregated MoE metrics and thermal signals from the results\n",
    "aggregated_moe_metrics = baseline_results.get('aggregated_moe_metrics', {})\n",
    "thermal_signals = baseline_results.get('thermal_signals', [])\n",
    "\n",
    "logging.info(\"\\n--- Detailed MoE Metrics Analysis ---\")\n",
    "if aggregated_moe_metrics:\n",
    "    for key, values_list in aggregated_moe_metrics.items():\n",
    "        if not values_list:\n",
    "            print(f\"  {key}: No data collected\")\n",
    "            continue\n",
    "\n",
    "        # Check if values_list is actually a list before accessing elements\n",
    "        if not isinstance(values_list, list):\n",
    "             # If it's not a list, it's likely a single scalar value already\n",
    "             print(f\"  {key.replace('avg_', '')}: {values_list}\")\n",
    "             continue\n",
    "\n",
    "        # Handle different types of aggregated metrics (assuming values_list is now a list)\n",
    "        if 'usage_current' in key and isinstance(values_list[0], list):\n",
    "            # Expert usage is a list of counts per expert per batch\n",
    "            try:\n",
    "                avg_usage_per_expert = np.mean([np.array(v) for v in values_list], axis=0)\n",
    "                print(f\"  Average {key.replace('avg_', '')} across batches: {avg_usage_per_expert}\")\n",
    "            except Exception as e:\n",
    "                 logging.warning(f\"Could not average list metric {key}: {e}\")\n",
    "                 print(f\"  Raw {key}: {values_list}\")\n",
    "\n",
    "        elif 'timings_ms' in key and isinstance(values_list[0], float):\n",
    "             # Expert batch timings are floats per expert per batch (aggregated by sub_key)\n",
    "             avg_timing = np.mean(values_list)\n",
    "             print(f\"  Average {key.replace('avg_', '')} across batches: {avg_timing:.2f} ms\")\n",
    "\n",
    "        elif 'cumulative_timings_ms' in key and isinstance(values_list[0], float):\n",
    "             # Cumulative timings (aggregated by sub_key) - the last value is the total\n",
    "             # Note: The aggregation logic stored the *last* cumulative value per batch,\n",
    "             # so we can just take the mean of these last values across batches,\n",
    "             # or, more accurately, the sum if we wanted total cumulative time across all batches.\n",
    "             # Let's just print the averaged 'last' cumulative value for simplicity here.\n",
    "             avg_last_cumulative_timing = np.mean(values_list)\n",
    "             print(f\"  Average Final {key.replace('avg_', '')}: {avg_last_cumulative_timing:.2f} ms\")\n",
    "\n",
    "        elif isinstance(values_list[0], (int, float)):\n",
    "            # Other simple scalar metrics\n",
    "            print(f\"  {key.replace('avg_', '')}: {np.mean(values_list):.4f}\")\n",
    "        else:\n",
    "            print(f\"  Raw {key}: {values_list}\")\n",
    "\n",
    "else:\n",
    "    print(\"No aggregated MoE metrics collected.\")\n",
    "\n",
    "print(\"\\n--- Thermal Signal Analysis ---\")\n",
    "if thermal_signals:\n",
    "    temperatures = [s.temperature for s in thermal_signals]\n",
    "    power_draws = [s.power_draw for s in thermal_signals]\n",
    "    thermal_states = [s.thermal_state for s in thermal_signals]\n",
    "    power_modes = [s.power_mode for s in thermal_signals]\n",
    "\n",
    "    print(f\"  Total Thermal Signals Collected: {len(thermal_signals)}\")\n",
    "    print(f\"  Temperature: Avg={np.mean(temperatures):.1f}°C, Max={np.max(temperatures):.1f}°C, Min={np.min(temperatures):.1f}°C\")\n",
    "    print(f\"  Power Draw: Avg={np.mean(power_draws):.1f}W, Max={np.max(power_draws):.1f}W, Min={np.min(power_draws):.1f}W\")\n",
    "\n",
    "    # Summarize thermal states and power modes\n",
    "    thermal_state_counts = {}\n",
    "    for state in ThermalState:\n",
    "        count = thermal_states.count(state)\n",
    "        if count > 0:\n",
    "            thermal_state_counts[state.value] = count\n",
    "    print(f\"  Thermal State Distribution: {thermal_state_counts}\")\n",
    "\n",
    "    power_mode_counts = {}\n",
    "    for mode in PowerMode:\n",
    "        count = power_modes.count(mode)\n",
    "        if count > 0:\n",
    "            power_mode_counts[mode.value] = count\n",
    "    print(f\"  Power Mode Distribution: {power_mode_counts}\")\n",
    "\n",
    "else:\n",
    "    print(\"No thermal signals collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dummy dataset\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n=1000, d_model=64):\n",
    "        self.data = torch.randn(n, d_model)\n",
    "        self.targets = torch.randn(n, d_model)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Dummy transformer wrapper\n",
    "class MoETransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_experts, top_k, thermal_signal_generator):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "        experts = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(num_experts)])\n",
    "        self.moe_layer = SimpleMoELayer(self.gate, experts, top_k, thermal_signal_generator=thermal_signal_generator)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe_layer(x)\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "d_model = 64\n",
    "num_experts = 8\n",
    "top_k = 2\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "dataset = DummyDataset(n=500, d_model=d_model)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "thermal_signal = ThermalSignalGenerator(device_id=0)\n",
    "model = MoETransformerBlock(d_model, num_experts, top_k, thermal_signal_generator=thermal_signal).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _, selected_experts = model(x)\n",
    "        task_loss = criterion(output, y)\n",
    "        energy_loss = compute_energy_loss(selected_expert_indices=selected_experts,\n",
    "                                          expert_profiles=thermal_signal.expert_profiles,\n",
    "                                          alpha=0.001)\n",
    "        loss = task_loss + energy_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} done. Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
